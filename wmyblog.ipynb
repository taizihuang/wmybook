{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "articleFile = './data/article_full.pkl'       \n",
    "commentFile=\"./data/comment_full.pkl\"\n",
    "\n",
    "df_article = pd.read_pickle(articleFile)\n",
    "df_comment = pd.read_pickle(commentFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep_list = [\n",
    "    ('&lt;','<'), ('&gt;','>'), ('&amp;','&'),\n",
    "    ('<p>','\\n'), ('</p>','\\n'), ('<br>','\\n'),('<br/>','\\n'),\n",
    "    ('%','\\%'), ('$','\\$'), ('&','\\&'),('#','\\#'), ('^','\\^'), ('_','\\_'), ('===','='),\n",
    "    ('<strike>','\\\\cancel{'), ('</strike>','}'),\n",
    "    #math\n",
    "    ('σ','$\\sigma$'), ('r\\^2','$r^2$'), ('λ','$\\lambda$'), ('π','$\\pi$'), ('r\\^4','$r^4$'),\n",
    "    ('∝','$\\propto$'), ('ρ','$\\\\rho$'), ('≈','$\\\\approx$'), ('\\^','\\^{}'),\n",
    "    #special\n",
    "    ('5d9478403b1a5b12c09b10aaadcdcdcb','empty')\n",
    "]\n",
    "rem_list = [\n",
    "    '\\r\\n','p=\"\">','<em>','</em>',\n",
    "    '</span>','<div>','</div>','div>','<h2','h2>',\n",
    "    '<strong>','</strong>','<code>','</code>','</font>','font color=\"#656565\" face=\"Microsoft YaHei, Arial\">',\n",
    "    '<div class=\"articlebox\">', '<div id=\"article\\_show\\_content\">',\n",
    "    '<div class=\"POST\" style=\"font-size:16px\">', '<p class=\"DATE\">',\n",
    "    '<p class=\"MsoNormal\">', '<p class=\"MsoNormal\" style=\"line-height:normal\">',\n",
    "    '<p class=\"MsoNormal\" style=\"margin-bottom:0.0001pt;line-height:normal\"',\n",
    "    '<p align=\"center\" class=\"MsoNormal\" style=\"text-align:center;line-height:normal\">',\n",
    "    ' style=\"font-size:11.5pt;letter-spacing:0.75pt\" target=\"\\_blank','\\n\\n>',\n",
    "    '<a href=\"https://www.huffingtonpost.com/entry/trump-trade-war\\\\_us\\\\_5ac53929e4b09ef3b2432f64\" title=\"這裏\"></a>',\n",
    "]\n",
    "    \n",
    "img_list = [\n",
    "    ('f_26462958_1'), ('f_25350703_1'), ('2f50f0bffaf439ca5adac6dffafb4618'),\n",
    "    ('ba77ae1763533d27063da5a3a6da38e0'), ('1255f7d9f3d7178b872880a1ffb96277'),\n",
    "    ('1e42c210bafb4887d03c25669817fcd7'), ('14f1704e177d6c3985238567b5a613c0'),\n",
    "    ('29e192984e9ce0086e88a98be3705562'), ('ab6f21134e7dcba1cfbf2e494200f9ef'),\n",
    "    ('d39156c719714a726b82aae6048a3c41'), ('b314bf52394928e7e7fb213264129366'),\n",
    "    ('d400eb09ec690963cfd6d651805ad4f0'), ('c624e9ae06a66f951f3d346c7698e9a3'),\n",
    "]\n",
    "\n",
    "#\n",
    "content = \"\"\"\n",
    "\\\\documentclass[twocolumn]{ctexart}\n",
    "\\\\usepackage{ctex}\n",
    "\\\\usepackage{graphicx}\n",
    "\\\\usepackage{titlesec}\n",
    "\\\\usepackage[hyphens]{url}\n",
    "\\\\usepackage[colorlinks=true, urlcolor=blue, linkcolor=black]{hyperref}\n",
    "\\\\usepackage{geometry}\n",
    "\\\\usepackage{cancel}\n",
    "\\\\setCJKmainfont{SimSun}\n",
    "\\\\newCJKfontfamily\\Kai{KaiTi}\n",
    "\\\\newCJKfontfamily\\Hei{SimHei} \n",
    "\\\\setcounter{secnumdepth}{0}\n",
    "\\\\setcounter{tocdepth}{1}\n",
    "\\\\titleformat*{\\\\section}{\\\\centering\\\\Large\\\\bfseries }\n",
    "\\\\titleformat*{\\\\subsection}{\\\\centering}\n",
    "\\\\titlespacing*{\\\\subsection} {0pt}{0pt}{10ex}\n",
    "\\\\geometry{a4paper, scale=0.85}\n",
    "\\\\begin{document}\n",
    "\\\\begin{titlepage}\\\\vspace*{8cm}\\\\begin{center}{\\\\Huge\\\\bfseries\\\\heiti 王孟源文集}(v23.6.14)\\\\end{center}\\\\end{titlepage}\\\\newpage\n",
    "\\\\tableofcontents\n",
    "\\\\newpage\n",
    "\\\\pagestyle{plain}\n",
    "\"\"\"\n",
    "df_article = df_article.sort_values('art_date',ascending=True)\n",
    "for idx in df_article.index:\n",
    "    title = df_article.loc[idx,'title']\n",
    "    date = df_article.loc[idx,'art_date'].strftime('%Y-%m-%d %H:%M')\n",
    "    post = df_article.loc[idx,'post']\n",
    "    if len(post) < 100:\n",
    "        continue\n",
    "\n",
    "    for rep in rep_list:\n",
    "        post = post.replace(*rep)\n",
    "\n",
    "    post = re.sub(r'<span .*?font-size.*?>','',post)\n",
    "    post = re.sub(r'<span .*?font-family.*?>','',post)\n",
    "    post = re.sub(r'<span style=.*?>','',post)\n",
    "    post = re.sub(r'<div style=.*?>','',post)\n",
    "    post = re.sub(r'<p style=.*?>','',post)\n",
    "    post = re.sub(r'<font face=.*?>','',post)\n",
    "\n",
    "    post = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>http(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{http\\2}}}',post)\n",
    "    post = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{\\2}',post)\n",
    "    post = re.sub(f'<a href=\"(.*?)\">',r'\\\\url{\\1}',post)\n",
    "    post = re.sub(f'<span .*標楷體.*?>(.*)<\\/span>',r'{\\\\Kai{\\1}}',post)\n",
    "    post = re.sub(r'<strong>(.*)<\\/strong>',r'{\\\\centering\\\\Hei{\\1}}',post)\n",
    "    post = re.sub(r'<span .*?underline.*?>(.*)<\\/span>',r'\\\\uline{\\1}',post)\n",
    "\n",
    "    for rem in rem_list:\n",
    "        post = post.replace(rem,'')\n",
    "\n",
    "    #image\n",
    "    matches = re.findall('<img .*src=\"(.*)\".*\\/>',post)\n",
    "    for match in matches:\n",
    "        post = post.replace(match, match.replace('\\_','_').replace('.gif','.jpg'))\n",
    "        for img in img_list:\n",
    "            post = post.replace(f'{img}.jpg',f'{img}.png')\n",
    "    post = re.sub(f'<img .*src=\"(.*?)\".*\\/>',r'\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{../html/\\1}\\\\end{figure}',post)\n",
    "    post = post.replace('\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{../html/./img/empty.png}\\\\end{figure}','')\n",
    "    post = post.replace('\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{../html/./img/empty.jpg}\\\\end{figure}','')\n",
    "\n",
    "    #table\n",
    "    if '<table' in post:\n",
    "        loc1 = post.find('<table')\n",
    "        loc2 = post.find('/table>')\n",
    "        post = post.replace(post[loc1:loc2+7],'\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 1\\\\linewidth]{../html/img/table.png}\\\\end{figure}')\n",
    "\n",
    "    #list\n",
    "    if '<ol>' in post:\n",
    "        post = post.replace('<ol>','\\\\begin{enumerate}\\n').replace('</ol>','\\\\end{enumerate}\\n').replace('<li>','\\\\item ').replace('</li>','\\n').replace('<p style=\"margin-left:30px\">','\\n')\n",
    "\n",
    "    #special\n",
    "    post = post.replace('P<sub>R</sub>(V)','$P^R(V)$')\n",
    "    post = post.replace('</','').replace('a>','')\n",
    "    \n",
    "    content += f\"\\\\twocolumn[\\\\begin{{@twocolumnfalse}}\\n\\\\section{{{title}}}\\n\\\\subsection{{{date}}}\\n\\\\end{{@twocolumnfalse}}]\"\n",
    "    content += post\n",
    "\n",
    "content += '\\n \\\\end{document}'\n",
    "\n",
    "with open('article.tex','w',encoding='utf8') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': {'142302095': \"(r'<table>(.*)</table>', '\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 1\\\\linewidth]{./img/table.png}\\\\end{figure}')\"}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('errata.json', 'r', encoding='utf8') as f:\n",
    "    content = f.read()\n",
    "json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in {1: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.environ['https_proxy'] = '127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = '127.0.0.1:7890'\n",
    "\n",
    "url = 'https://drive.google.com/drive/folders/1eg78LVciM913PhvRtsgtWV3VDLojynDA'\n",
    "doc = BeautifulSoup(requests.get(url).content, features=\"lxml\")\n",
    "df = pd.DataFrame()\n",
    "for i in doc.findAll(\"div\", {'data-target':\"doc\"}):\n",
    "    if i.find(\"div\",{'role':\"link\"}):\n",
    "        i.find(\"div\",{'role':\"link\"}).decompose()\n",
    "    df = pd.concat([df, pd.DataFrame(data={'filename': i.text, 'id': i['data-id']}, index=[0])], ignore_index=True)  \n",
    "# L = tasker.run([saveScript(df.loc[idx, 'filename'][:6], df.loc[idx, 'id'], proxy) for idx in df.index])\n",
    "# print('transcript downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Doxs\\github\\wmyblog\\pdf\\wmyblog.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Doxs/github/wmyblog/pdf/wmyblog.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwmyblog_coron\u001b[39;00m \u001b[39mimport\u001b[39;00m table2tag\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from wmyblog_coron import table2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_table = pd.read_excel('./data/table.xlsx',index_col=0)\n",
    "df_tag = pd.DataFrame()\n",
    "\n",
    "for i in range(round(len(df_table.columns)/2)):\n",
    "    df_tag = pd.concat([df_tag, df_table[[f'code_{i}',f'tag_{i}']].rename(columns={f'code_{i}':'code',f'tag_{i}':'tag'})],axis=0)\n",
    "df_tag = df_tag.loc[~df_tag.code.isna()].reset_index(drop=True)\n",
    "df_tag['md5'] = df_tag['code'].apply(lambda x: x[-32:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag[['md5','tag']].to_pickle('./data/tag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Apikey':'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNqbG9za2pjb2dya3ZocGtmb296Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODYwMjIyNjIsImV4cCI6MjAwMTU5ODI2Mn0.peYwcTSZcDd3SvG5Rh99jlM7uyHkUjq1klvqRt2vF5c',\n",
    "    'Authorization':'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNqbG9za2pjb2dya3ZocGtmb296Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODYwMjIyNjIsImV4cCI6MjAwMTU5ODI2Mn0.peYwcTSZcDd3SvG5Rh99jlM7uyHkUjq1klvqRt2vF5c'\n",
    "}\n",
    "tag_dict = json.loads(requests.get('https://cjloskjcogrkvhpkfooz.supabase.co/rest/v1/tag?select=*&order=created_at.desc&limit=200',headers=headers).content)\n",
    "df_tag_new = pd.DataFrame(tag_dict).rename(columns={'id':'md5'})[['md5','tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep_list = [\n",
    "    ('&lt;','<'), ('&gt;','>'), ('&amp;','&'),\n",
    "    ('<p>','\\n'), ('</p>','\\n'), ('<br>','\\n'),('<br/>','\\n'),\n",
    "    ('%','\\%'), ('$','\\$'), ('&','\\&'),('#','\\#'), ('^','\\^'), ('_','\\_'), ('===','='),\n",
    "    ('<strike>','\\\\cancel{'), ('</strike>','}'),\n",
    "    #math\n",
    "    ('σ','$\\sigma$'), ('r\\^2','$r^2$'), ('λ','$\\lambda$'), ('π','$\\pi$'), ('r\\^4','$r^4$'),\n",
    "    ('∝','$\\propto$'), ('ρ','$\\\\rho$'), ('≈','$\\\\approx$'), ('\\^','\\^{}'),\n",
    "    #special\n",
    "    ('5d9478403b1a5b12c09b10aaadcdcdcb','empty')\n",
    "]\n",
    "rem_list = [\n",
    "    '\\r\\n','p=\"\">','<em>','</em>',\n",
    "    '</span>','<div>','</div>','div>','<h2','h2>',\n",
    "    '<strong>','</strong>','<code>','</code>','</font>','font color=\"#656565\" face=\"Microsoft YaHei, Arial\">',\n",
    "    '<div class=\"articlebox\">', '<div id=\"article\\_show\\_content\">',\n",
    "    '<div class=\"POST\" style=\"font-size:16px\">', '<p class=\"DATE\">',\n",
    "    '<p class=\"MsoNormal\">', '<p class=\"MsoNormal\" style=\"line-height:normal\">',\n",
    "    '<p class=\"MsoNormal\" style=\"margin-bottom:0.0001pt;line-height:normal\"',\n",
    "    '<p align=\"center\" class=\"MsoNormal\" style=\"text-align:center;line-height:normal\">',\n",
    "    ' style=\"font-size:11.5pt;letter-spacing:0.75pt\" target=\"\\_blank','\\n\\n>',\n",
    "    '<a href=\"https://www.huffingtonpost.com/entry/trump-trade-war\\\\_us\\\\_5ac53929e4b09ef3b2432f64\" title=\"這裏\"></a>',\n",
    "]\n",
    "    \n",
    "img_list = [\n",
    "    ('f_26462958_1'), ('f_25350703_1'), ('2f50f0bffaf439ca5adac6dffafb4618'),\n",
    "    ('ba77ae1763533d27063da5a3a6da38e0'), ('1255f7d9f3d7178b872880a1ffb96277'),\n",
    "    ('1e42c210bafb4887d03c25669817fcd7'), ('14f1704e177d6c3985238567b5a613c0'),\n",
    "    ('29e192984e9ce0086e88a98be3705562'), ('ab6f21134e7dcba1cfbf2e494200f9ef'),\n",
    "    ('d39156c719714a726b82aae6048a3c41'), ('b314bf52394928e7e7fb213264129366'),\n",
    "    ('d400eb09ec690963cfd6d651805ad4f0'), ('c624e9ae06a66f951f3d346c7698e9a3'),\n",
    "]\n",
    "\n",
    "def formatArticle(df_article, idx):\n",
    "    title = df_article.loc[idx,'title']\n",
    "    date = df_article.loc[idx,'art_date'].strftime('%Y-%m-%d %H:%M')\n",
    "    header = f\"\\\\twocolumn[\\\\begin{{@twocolumnfalse}}\\n\\\\section{{{title}}}\\n\\\\subsection{{王孟源\\\\break {date}}}\\n\\\\end{{@twocolumnfalse}}]\"\n",
    "    post = df_article.loc[idx,'post']\n",
    "    if len(post) < 250:\n",
    "        return ''\n",
    "\n",
    "    for rep in rep_list:\n",
    "        post = post.replace(*rep)\n",
    "\n",
    "    post = re.sub(r'<span .*?font-size.*?>','',post)\n",
    "    post = re.sub(r'<span .*?font-family.*?>','',post)\n",
    "    post = re.sub(r'<span style=.*?>','',post)\n",
    "    post = re.sub(r'<div style=.*?>','',post)\n",
    "    post = re.sub(r'<p style=.*?>','',post)\n",
    "    post = re.sub(r'<font face=.*?>','',post)\n",
    "\n",
    "    post = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>http(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{http\\2}}}',post)\n",
    "    post = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{\\2}',post)\n",
    "    post = re.sub(f'<a href=\"(.*?)\">',r'\\\\url{\\1}',post)\n",
    "    post = re.sub(f'<span .*標楷體.*?>(.*)<\\/span>',r'{\\\\Kai{\\1}}',post)\n",
    "    post = re.sub(r'<strong>(.*)<\\/strong>',r'{\\\\centering\\\\Hei{\\1}}',post)\n",
    "    post = re.sub(r'<span .*?underline.*?>(.*)<\\/span>',r'\\\\uline{\\1}',post)\n",
    "\n",
    "    for rem in rem_list:\n",
    "        post = post.replace(rem,'')\n",
    "\n",
    "    #image\n",
    "    matches = re.findall('<img .*src=\"(.*)\".*\\/>',post)\n",
    "    for match in matches:\n",
    "        post = post.replace(match, match.replace('\\_','_').replace('.gif','.jpg'))\n",
    "        for img in img_list:\n",
    "            post = post.replace(f'{img}.jpg',f'{img}.png')\n",
    "    post = re.sub(f'<img .*src=\"(.*?)\".*\\/>',r'\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{./\\1}\\\\end{figure}',post)\n",
    "    post = post.replace('\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{./img/empty.png}\\\\end{figure}','')\n",
    "    post = post.replace('\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 0.9\\\\linewidth]{./img/empty.jpg}\\\\end{figure}','')\n",
    "\n",
    "    #table\n",
    "    if '<table' in post:\n",
    "        loc1 = post.find('<table')\n",
    "        loc2 = post.find('/table>')\n",
    "        post = post.replace(post[loc1:loc2+7],'\\\\begin{figure}[h]\\\\centering\\\\includegraphics[width = 1\\\\linewidth]{./img/table.png}\\\\end{figure}')\n",
    "\n",
    "    #list\n",
    "    if '<ol>' in post:\n",
    "        post = post.replace('<ol>','\\\\begin{enumerate}\\n').replace('</ol>','\\\\end{enumerate}\\n').replace('<li>','\\\\item ').replace('</li>','\\n').replace('<p style=\"margin-left:30px\">','\\n')\n",
    "\n",
    "    #special\n",
    "    post = post.replace('P<sub>R</sub>(V)','$P^R(V)$')\n",
    "    post = post.replace('</','').replace('a>','')\n",
    "    \n",
    "    return header + post\n",
    "#\n",
    "\n",
    "def formatComment(df_id_comment, idx):\n",
    "    nickname = df_id_comment.loc[idx,'nickname']\n",
    "    comment = df_id_comment.loc[idx,'comment'].replace('\\n','\\n\\n')\n",
    "    comment_date = df_id_comment.loc[idx,'comment_date'].strftime('%Y/%m/%d %H:%M')\n",
    "    reply = df_id_comment.loc[idx,'reply'].replace('<br>','<br><br>')\n",
    "    if pd.isnull(df_id_comment.loc[idx,'latest_reply_date']):\n",
    "        reply_date = ''\n",
    "    else:\n",
    "        reply_date = df_id_comment.loc[idx,'latest_reply_date'].strftime('%Y/%m/%d %H:%M')\n",
    "\n",
    "\n",
    "    # comment = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>http(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{http\\2}}}',comment)\n",
    "    # comment = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{\\2}',comment)\n",
    "    comment = re.sub(r'(https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b[-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{\\1}}}',comment)\n",
    "\n",
    "    reply = re.sub(r'<span .*?font-size.*?>','',reply)\n",
    "    reply = re.sub(r'<span .*?font-family.*?>','',reply)\n",
    "    reply = re.sub(r'<span style=.*?>','',reply)\n",
    "    reply = re.sub(r'<div style=.*?>','',reply)\n",
    "    reply = re.sub(r'<p style=.*?>','',reply)\n",
    "    reply = re.sub(r'<font face=.*?>','',reply)\n",
    "\n",
    "    reply = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>http(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{http\\2}}}',reply)\n",
    "    reply = re.sub(f'[<span .*>]*<a\\ +href=\"(.+?)\".*?>(.+?)<.*?\\/a>[<\\/span>]*',r'\\\\href{\\1}{\\2}',reply)\n",
    "    reply = re.sub(f'<a href=\"(.*?)\">',r'\\\\url{\\1}',reply)\n",
    "    reply = re.sub(f'<span .*標楷體.*?>(.*)<\\/span>',r'{\\\\Kai{\\1}}',reply)\n",
    "    reply = re.sub(r'<strong>(.*)<\\/strong>',r'{\\\\centering\\\\Hei{\\1}}',reply)\n",
    "    reply = re.sub(r'<span .*?underline.*?>(.*)<\\/span>',r'\\\\uline{\\1}',reply)\n",
    "    reply = re.sub(r'(https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b[-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)',r'\\\\href{\\1}{链接\\\\footnote{\\\\url{\\1}}}',reply)\n",
    "\n",
    "\n",
    "    for rep in rep_list:\n",
    "        nickname = nickname.replace(*rep)\n",
    "        comment = comment.replace(*rep)\n",
    "        reply = reply.replace(*rep)\n",
    "\n",
    "    for rem in rem_list:\n",
    "        reply = reply.replace(rem,'')\n",
    "\n",
    "    if reply != '':\n",
    "        content = f\"\\\\textit{{\\\\hfill\\\\noindent\\\\small {comment_date} 提问；{reply_date} 回答}}\\n\\n\"\n",
    "        content += f\"{{\\\\noindent[{idx+1}.]\\\\ \\\\ \\\\ \\\\ \\\\Kai {nickname} 问：{comment}}}\\n\\n\"\n",
    "        content += f\"{{\\\\Hei 答}}：{reply}\\\\\\\\\\n\\n\"\n",
    "    else:\n",
    "        content = f\"\\\\textit{{\\\\hfill\\\\noindent\\\\small {comment_date} 提问}}\\n\\n\"\n",
    "        content += f\"{{\\\\noindent[{idx+1}.]\\\\ \\\\ \\\\ \\\\ \\\\Kai {nickname} 问：{comment}}}\\n\\n\"\n",
    "\n",
    "    \n",
    "    return content\n",
    "\n",
    "\n",
    "content = \"\"\"\n",
    "\\\\documentclass[twocolumn]{ctexart}\n",
    "\\\\usepackage{ctex}\n",
    "\\\\usepackage{graphicx}\n",
    "\\\\usepackage{titlesec}\n",
    "\\\\usepackage[hyphens]{url}\n",
    "\\\\usepackage[colorlinks=true, urlcolor=blue, linkcolor=black]{hyperref}\n",
    "\\\\usepackage{geometry}\n",
    "\\\\usepackage{cancel}\n",
    "\\\\setmainfont{Times New Roman}\n",
    "\\\\setCJKmainfont{SimSun}\n",
    "\\\\newCJKfontfamily\\Kai{KaiTi}\n",
    "\\\\newCJKfontfamily\\Hei{SimHei} \n",
    "\\\\setcounter{secnumdepth}{0}\n",
    "\\\\setcounter{tocdepth}{1}\n",
    "\\\\titleformat*{\\\\section}{\\\\centering\\\\Large\\\\bfseries }\n",
    "\\\\titleformat*{\\\\subsection}{\\\\centering}\n",
    "\\\\titlespacing*{\\\\subsection} {0pt}{0pt}{10ex}\n",
    "\\\\geometry{a4paper, scale=0.85}\n",
    "\\\\begin{document}\n",
    "\\\\begin{titlepage}\\\\vspace*{8cm}\\\\begin{center}{\\\\Huge\\\\bfseries\\\\heiti 王孟源文集}(v0.1.0)\\\\end{center}\\\\end{titlepage}\\\\newpage\n",
    "\\\\tableofcontents\n",
    "\\\\newpage\n",
    "\\\\pagestyle{plain}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for idx in df_article.index[:100]:\n",
    "    id = df_article.loc[idx, 'id']\n",
    "    df_article_id = df_article.loc[df_article.id == id].reset_index(drop=True)\n",
    "    df_comment_id = df_comment.loc[df_comment.id == id]\n",
    "    df_comment_id = df_comment_id.loc[~df_comment.comment.str.contains('<strike')]\n",
    "    # df_comment_id = df_comment_id.loc[df_comment.reply != '']\n",
    "    df_comment_id = df_comment_id.sort_values('comment_date',ascending=True).reset_index(drop=True)\n",
    "\n",
    "    article = formatArticle(df_article_id, 0) \n",
    "    if article != '':\n",
    "        content += article + '\\n\\n'\n",
    "        content += f'\\\\section{{{len(df_comment_id)}条问答}}\\n\\n'\n",
    "\n",
    "        for idx in df_comment_id.index:\n",
    "            comment = formatComment(df_comment_id, idx)\n",
    "            # comment = comment.replace('\\n','\\n\\n')\n",
    "            # comment = comment.replace('')\n",
    "            content += comment\n",
    "\n",
    "content = content.replace('{\\Hei 答}：\\n\\n',r'{\\Hei 答}：')\n",
    "content = content.replace('<span id=\"mainbody\">','')\n",
    "content = content.replace(r'\\社',r'\\\\社')\n",
    "content = content.replace(r'\\判',r'\\\\判')\n",
    "\n",
    "content += '\\n \\\\end{document}'\n",
    "\n",
    "with open(f'wmybook.tex','w',encoding='utf8') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\\\Hei 答}：好的，謝謝。《UDN》的網絡管理一直不回復我的去信，看來必須自己動手修復了。請從“世界對白”那裏獲得我的電郵，私下和我聯絡，以便討論細節。\\n\\\\\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\\Hei 答}：\n",
    "\n",
    "好的，謝謝。\n",
    "\n",
    "《UDN》的網絡管理一直不回復我的去信，看來必須自己動手修復了。請從“世界對白”那裏獲得我的電郵，私下和我聯絡，以便討論細節。\n",
    "\\\\\n",
    "\"\"\".replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "财阀\\社会主义政见的Sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xyga0aQ9OveaYxoCxWo89AUGEhlh4GRkjLSjrGV41rmh0fqk5JM1SX1osRztUUqzj4ZXXQ4AJttLSbBSvEST5zd2qPsij\n",
    "WVzc6arMF45W56TcgFQqjZL7LbEa_0cYEIcmujIZPWP0YwX6UjAZYxu1/w408-\n",
    "h338/Medvedev-Putin.jpg\n",
    "\n",
    "可以用來\\判斷打的程度\n",
    "\n",
    "外 交 部 介 绍 中 美 元 首 会\n",
    "晤 成 果： 放 宽 金 融 业 市 \n",
    "\n",
    "/noteshare?id=a21f4c3f44eeea0f3f86e7948512525d&sub=40E2F646692742EB87CDF9103F\n",
    "\n",
    "大家聊的这么热闹,我再来补充点一孔之\n",
    "\n",
    "-lags-peer-countries-mobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def extract(response):\n",
    "    doc = response.decode('utf8') \n",
    "\n",
    "    string_left = 'DOCS_modelChunk = [{'\n",
    "    string_right = '},{\"'\n",
    "    text = ''\n",
    "    while string_left in doc:\n",
    "        loc1 = doc.index(string_left)\n",
    "        loc2 = doc[loc1:].index(string_right)\n",
    "        text += json.loads(doc[loc1+18:loc1+loc2] + '}]')[0]['s']\n",
    "        doc = doc[loc1+loc2+2:]\n",
    "    return text\n",
    "\n",
    "df = pd.read_pickle('transcript.pkl')\n",
    "df_info = pd.read_pickle('trascript_info.pkl')\n",
    "df['id'] = df['url'].map(lambda x: x.split('/')[-2])\n",
    "df_merge = pd.merge(df, df_info, on='id')\n",
    "df_merge['title'] = df_merge['filename'].map(lambda x: x.split('已隱藏')[0].split(']')[-1].replace('✅','').replace('.docx',''))\n",
    "df_merge['art_date'] = df_merge['filename'].map(lambda x: '20'+ x.split('已隱藏')[0].split('[')[0])\n",
    "df_merge['text'] = df_merge['response'].map(extract)\n",
    "df_merge = df_merge.sort_values('art_date',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "\\\\documentclass[twocolumn]{ctexart}\n",
    "\\\\usepackage{ctex}\n",
    "\\\\usepackage{graphicx}\n",
    "\\\\usepackage{titlesec}\n",
    "\\\\usepackage[hyphens]{url}\n",
    "\\\\usepackage[colorlinks=true, urlcolor=blue, linkcolor=black]{hyperref}\n",
    "\\\\usepackage{geometry}\n",
    "\\\\usepackage{cancel}\n",
    "\\\\setCJKmainfont{SimSun}\n",
    "\\\\newCJKfontfamily\\Kai{KaiTi}\n",
    "\\\\newCJKfontfamily\\Hei{SimHei} \n",
    "\\\\setcounter{secnumdepth}{0}\n",
    "\\\\setcounter{tocdepth}{1}\n",
    "\\\\titleformat*{\\\\section}{\\\\centering\\\\Large\\\\bfseries }\n",
    "\\\\titleformat*{\\\\subsection}{\\\\centering}\n",
    "\\\\titlespacing*{\\\\subsection} {0pt}{0pt}{10ex}\n",
    "\\\\geometry{a4paper, scale=0.85}\n",
    "\\\\begin{document}\n",
    "\\\\begin{titlepage}\\\\vspace*{8cm}\\\\begin{center}{\\\\Huge\\\\bfseries\\\\heiti 王孟源访谈}(v0.1.0)\\\\end{center}\\\\end{titlepage}\\\\newpage\n",
    "\\\\tableofcontents\n",
    "\\\\newpage\n",
    "\\\\pagestyle{plain}\n",
    "\"\"\"\n",
    "\n",
    "rep_list = [('&lt;','<'), ('&gt;','>'), ('&amp;','&'),\n",
    "('<p>','\\n'), ('</p>','\\n'), ('<br>','\\n'),('<br/>','\\n'),\n",
    "('%','\\%'), ('$','\\$'), ('&','\\&'),('#','\\#'), ('^','\\^'), ('_','\\_'), ('===','='),\n",
    "('<strike>','\\\\cancel{'), ('</strike>','}')]\n",
    "\n",
    "for idx in df_merge.index:\n",
    "    title = df_merge.loc[idx,'title'].replace(' ','、')\n",
    "    date = df_merge.loc[idx,'art_date']\n",
    "    text = df_merge.loc[idx,'text']\n",
    "    for rep in rep_list:\n",
    "        text = text.replace(*rep)\n",
    "    \n",
    "    content += f\"\\\\twocolumn[\\\\begin{{@twocolumnfalse}}\\n\\\\section{{{title}}}\\n\\\\subsection{{{date}}}\\n\\\\end{{@twocolumnfalse}}]\"\n",
    "    content += text.replace('\\n','\\n\\n').replace('\u000b','').replace('Putin}','Putin').replace('\\源源','/源源')\n",
    "    content\n",
    "\n",
    "content += '\\n \\\\end{document}'\n",
    "\n",
    "with open('transcript.tex','w',encoding='utf8') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "python wmybook.py && C:\\texlive\\2024\\bin\\windows\\xelatex -interaction nonstopmode comment.tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<strong>長期改革的方向</strong>\\n\\n\\n從前述美國的前車之鑒，我們可以總結'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "post = '\\n\\n<strong>長期改革的方向</strong>\\n\\n\\n從前述美國的前車之鑒，我們可以總結'\n",
    "rep = r\"\"\"(r'<span .*?>((\\n|.)*)<\\/span>',r'\\1')\"\"\"\n",
    "match = re.sub(*eval(rep), post)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span .*?>((\\\\n|.)*)<\\\\/span>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(r\"(r'<span .*?>((\\n|.)*)<\\/span>')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6c8f846148a3e4d140e6ddf63c190cff559dcf260a4a21539f0978f2b58638c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
